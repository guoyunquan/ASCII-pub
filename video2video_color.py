import cv2
import numpy as np
from PIL import Image, ImageFont, ImageDraw, ImageOps
from fastapi import File, UploadFile, APIRouter, Form, WebSocket, WebSocketDisconnect
import os
import uuid
import time
import asyncio
from fastapi.responses import JSONResponse
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing
from functools import partial
import json
from typing import Dict
import subprocess
import shutil
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from datetime import datetime, timedelta
import glob

# å‡è®¾å…¶ä»–å¯¼å…¥å’Œå‡½æ•°ä¿æŒä¸å˜
video = APIRouter()

# WebSocketè¿æ¥ç®¡ç†
class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}

    async def connect(self, websocket: WebSocket, task_id: str):
        await websocket.accept()
        self.active_connections[task_id] = websocket

    def disconnect(self, task_id: str):
        if task_id in self.active_connections:
            del self.active_connections[task_id]

    async def send_progress(self, task_id: str, progress: float, message: str = ""):
        if task_id in self.active_connections:
            try:
                await self.active_connections[task_id].send_text(json.dumps({
                    "type": "progress",
                    "progress": progress,
                    "message": message
                }))
            except:
                # è¿æ¥å·²æ–­å¼€ï¼Œç§»é™¤
                self.disconnect(task_id)

    async def send_completed(self, task_id: str, video_url: str):
        if task_id in self.active_connections:
            try:
                await self.active_connections[task_id].send_text(json.dumps({
                    "type": "completed",
                    "video_url": video_url
                }))
            except:
                self.disconnect(task_id)

    async def send_error(self, task_id: str, error_message: str):
        if task_id in self.active_connections:
            try:
                await self.active_connections[task_id].send_text(json.dumps({
                    "type": "error",
                    "message": error_message
                }))
            except:
                self.disconnect(task_id)

    async def send_error(self, task_id: str, error_message: str):
        if task_id in self.active_connections:
            try:
                await self.active_connections[task_id].send_text(json.dumps({
                    "type": "error",
                    "message": error_message
                }))
            except:
                self.disconnect(task_id)

manager = ConnectionManager()

# ä»»åŠ¡çŠ¶æ€ç®¡ç†
task_status: Dict[str, dict] = {}

# å®šæ—¶æ¸…ç†è°ƒåº¦å™¨
scheduler = AsyncIOScheduler()

async def cleanup_old_videos():
    """
    æ¸…ç†è¶…è¿‡24å°æ—¶çš„åª’ä½“æ–‡ä»¶ï¼ˆè§†é¢‘å’Œå›¾ç‰‡ï¼‰
    """
    try:
        data_dir = "data/"
        if not os.path.exists(data_dir):
            print("dataç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¸…ç†")
            return
        
        # è®¡ç®—24å°æ—¶å‰çš„æ—¶é—´æˆ³
        cutoff_time = datetime.now() - timedelta(hours=24)
        cutoff_timestamp = cutoff_time.timestamp()
        
        # æŸ¥æ‰¾æ‰€æœ‰åª’ä½“æ–‡ä»¶ï¼ˆè§†é¢‘å’Œå›¾ç‰‡ï¼‰
        media_patterns = [
            os.path.join(data_dir, "*.mp4"),
            os.path.join(data_dir, "*.avi"),
            os.path.join(data_dir, "*.mov"),
            os.path.join(data_dir, "*_with_audio.mp4"),
            os.path.join(data_dir, "*_input.mp4"),
            os.path.join(data_dir, "*.jpg"),
            os.path.join(data_dir, "*.jpeg"),
            os.path.join(data_dir, "*.png"),
            os.path.join(data_dir, "*_input.jpg"),
            os.path.join(data_dir, "*_input.jpeg"),
            os.path.join(data_dir, "*_input.png")
        ]
        
        deleted_count = 0
        total_size_freed = 0
        
        for pattern in media_patterns:
            for file_path in glob.glob(pattern):
                try:
                    # è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                    file_mtime = os.path.getmtime(file_path)
                    
                    # å¦‚æœæ–‡ä»¶è¶…è¿‡24å°æ—¶
                    if file_mtime < cutoff_timestamp:
                        # è·å–æ–‡ä»¶å¤§å°
                        file_size = os.path.getsize(file_path)
                        
                        # åˆ é™¤æ–‡ä»¶
                        os.remove(file_path)
                        
                        deleted_count += 1
                        total_size_freed += file_size
                        
                        print(f"å·²åˆ é™¤è¿‡æœŸæ–‡ä»¶: {os.path.basename(file_path)} ({file_size/1024/1024:.1f}MB)")
                        
                except Exception as e:
                    print(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
        
        if deleted_count > 0:
            print(f"æ¸…ç†å®Œæˆ! åˆ é™¤äº† {deleted_count} ä¸ªæ–‡ä»¶ï¼Œé‡Šæ”¾ç©ºé—´ {total_size_freed/1024/1024:.1f}MB")
        else:
            print("å®šæ—¶æ¸…ç†æ£€æŸ¥å®Œæˆï¼Œæ²¡æœ‰å‘ç°éœ€è¦æ¸…ç†çš„è¿‡æœŸæ–‡ä»¶")
            
    except Exception as e:
        print(f"å®šæ—¶æ¸…ç†å¼‚å¸¸: {str(e)}")

def start_cleanup_scheduler():
    """
    å¯åŠ¨å®šæ—¶æ¸…ç†è°ƒåº¦å™¨
    """
    try:
        # æ·»åŠ å®šæ—¶ä»»åŠ¡ï¼šæ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œæ¸…ç†
        scheduler.add_job(
            cleanup_old_videos,
            'cron',
            hour=2,
            minute=0,
            id='daily_cleanup',
            replace_existing=True
        )
        
        # ä¹Ÿå¯ä»¥æ·»åŠ ä¸€ä¸ªå¯åŠ¨æ—¶ç«‹å³æ‰§è¡Œä¸€æ¬¡çš„ä»»åŠ¡
        scheduler.add_job(
            cleanup_old_videos,
            'date',
            run_date=datetime.now() + timedelta(seconds=30),  # å¯åŠ¨30ç§’åæ‰§è¡Œä¸€æ¬¡
            id='startup_cleanup',
            replace_existing=True
        )
        
        scheduler.start()
        print("å®šæ—¶æ¸…ç†è°ƒåº¦å™¨å·²å¯åŠ¨ - æ¯å¤©å‡Œæ™¨2ç‚¹è‡ªåŠ¨æ¸…ç†è¶…è¿‡24å°æ—¶çš„åª’ä½“æ–‡ä»¶")
        print("å¯åŠ¨æ¸…ç†ä»»åŠ¡å°†åœ¨30ç§’åæ‰§è¡Œä¸€æ¬¡")
        
    except Exception as e:
        print(f"å¯åŠ¨å®šæ—¶æ¸…ç†è°ƒåº¦å™¨å¤±è´¥: {str(e)}")

def stop_cleanup_scheduler():
    """
    åœæ­¢å®šæ—¶æ¸…ç†è°ƒåº¦å™¨
    """
    try:
        if scheduler.running:
            scheduler.shutdown()
            print("å®šæ—¶æ¸…ç†è°ƒåº¦å™¨å·²åœæ­¢")
    except Exception as e:
        print(f"åœæ­¢å®šæ—¶æ¸…ç†è°ƒåº¦å™¨å¤±è´¥: {str(e)}")

# éŸ³é¢‘åˆå¹¶å‡½æ•°
async def merge_audio_with_video(original_video_path: str, ascii_video_path: str, output_path: str, task_id: str = None) -> bool:
    """
    ä½¿ç”¨ ffmpeg å°†åŸå§‹è§†é¢‘çš„éŸ³é¢‘ä¸ç”Ÿæˆçš„ ASCII è§†é¢‘åˆå¹¶
    
    Args:
        original_video_path: åŸå§‹è§†é¢‘æ–‡ä»¶è·¯å¾„
        ascii_video_path: ç”Ÿæˆçš„ASCIIè§†é¢‘æ–‡ä»¶è·¯å¾„  
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸåˆå¹¶
    """
    try:
        # å‘é€è¿›åº¦ï¼šæ£€æŸ¥å·¥å…·
        if task_id:
            await manager.send_progress(task_id, 85, "æ£€æŸ¥éŸ³é¢‘å¤„ç†å·¥å…·...")
        
        # æ£€æŸ¥ ffmpeg æ˜¯å¦å¯ç”¨
        result = subprocess.run(['ffmpeg', '-version'], 
                              capture_output=True, text=True, timeout=10)
        if result.returncode != 0:
            print("ffmpeg ä¸å¯ç”¨ï¼Œè·³è¿‡éŸ³é¢‘åˆå¹¶")
            if task_id:
                await manager.send_progress(task_id, 90, "éŸ³é¢‘å·¥å…·ä¸å¯ç”¨ï¼Œè·³è¿‡éŸ³é¢‘å¤„ç†")
            return False
        
        # å‘é€è¿›åº¦ï¼šåˆ†æéŸ³é¢‘è½¨é“
        if task_id:
            await manager.send_progress(task_id, 87, "åˆ†æåŸè§†é¢‘éŸ³é¢‘è½¨é“...")
        
        print(f"å¼€å§‹åˆå¹¶éŸ³é¢‘...")
        print(f"   åŸå§‹è§†é¢‘: {original_video_path}")
        print(f"   ASCIIè§†é¢‘: {ascii_video_path}")
        print(f"   è¾“å‡ºè·¯å¾„: {output_path}")
        
        # ä¸´æ—¶è¾“å‡ºæ–‡ä»¶
        temp_output = f"{output_path}_temp.mp4"
        
        # å‘é€è¿›åº¦ï¼šåŒ¹é…éŸ³é¢‘è½¨é“
        if task_id:
            await manager.send_progress(task_id, 89, "åŒ¹é…éŸ³é¢‘è½¨é“ä¸è§†é¢‘æµ...")
        
        # ffmpeg å‘½ä»¤ï¼šå°† ASCII è§†é¢‘ä¸åŸå§‹è§†é¢‘çš„éŸ³é¢‘åˆå¹¶
        # -i è¾“å…¥1: ASCIIè§†é¢‘ (è§†é¢‘æµ)
        # -i è¾“å…¥2: åŸå§‹è§†é¢‘ (éŸ³é¢‘æµ)
        # -c:v copy: å¤åˆ¶è§†é¢‘æµï¼ˆä¸é‡æ–°ç¼–ç ï¼‰
        # -c:a aac: éŸ³é¢‘ç¼–ç ä¸ºaac
        # -map 0:v: ä½¿ç”¨ç¬¬ä¸€ä¸ªè¾“å…¥çš„è§†é¢‘æµ
        # -map 1:a: ä½¿ç”¨ç¬¬äºŒä¸ªè¾“å…¥çš„éŸ³é¢‘æµ
        # -shortest: ä»¥æœ€çŸ­æµä¸ºå‡†
        cmd = [
            'ffmpeg',
            '-i', ascii_video_path,    # ASCII è§†é¢‘ï¼ˆè§†é¢‘æµï¼‰
            '-i', original_video_path,  # åŸå§‹è§†é¢‘ï¼ˆéŸ³é¢‘æµï¼‰
            '-c:v', 'copy',            # å¤åˆ¶è§†é¢‘æµ
            '-c:a', 'aac',             # éŸ³é¢‘ç¼–ç 
            '-map', '0:v',             # ä½¿ç”¨ç¬¬ä¸€ä¸ªè¾“å…¥çš„è§†é¢‘
            '-map', '1:a?',            # ä½¿ç”¨ç¬¬äºŒä¸ªè¾“å…¥çš„éŸ³é¢‘ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            '-shortest',               # ä»¥æœ€çŸ­æµä¸ºå‡†
            '-y',                      # è¦†ç›–è¾“å‡ºæ–‡ä»¶
            temp_output
        ]
        
        # å‘é€è¿›åº¦ï¼šå¼€å§‹éŸ³é¢‘åˆå¹¶
        if task_id:
            await manager.send_progress(task_id, 91, "æ­£åœ¨åˆå¹¶éŸ³é¢‘ä¸è§†é¢‘...")
        
        # æ‰§è¡Œ ffmpeg å‘½ä»¤
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            # å‘é€è¿›åº¦ï¼šéªŒè¯åˆå¹¶ç»“æœ
            if task_id:
                await manager.send_progress(task_id, 94, "éªŒè¯éŸ³é¢‘åˆå¹¶ç»“æœ...")
            
            # æˆåŠŸï¼Œæ›¿æ¢åŸæ–‡ä»¶
            if os.path.exists(temp_output):
                shutil.move(temp_output, output_path)
                print(f"éŸ³é¢‘åˆå¹¶æˆåŠŸï¼")
                
                # å‘é€è¿›åº¦ï¼šéŸ³é¢‘åˆå¹¶å®Œæˆ
                if task_id:
                    await manager.send_progress(task_id, 96, "éŸ³é¢‘åˆå¹¶å®Œæˆï¼")
                    
                return True
            else:
                print(f"ä¸´æ—¶æ–‡ä»¶ä¸å­˜åœ¨: {temp_output}")
                if task_id:
                    await manager.send_progress(task_id, 90, "éŸ³é¢‘åˆå¹¶å¼‚å¸¸ï¼šä¸´æ—¶æ–‡ä»¶ä¸¢å¤±")
                return False
        else:
            print(f"ffmpeg æ‰§è¡Œå¤±è´¥:")
            print(f"   stdout: {result.stdout}")
            print(f"   stderr: {result.stderr}")
            
            # å‘é€è¿›åº¦ï¼šéŸ³é¢‘åˆå¹¶å¤±è´¥
            if task_id:
                await manager.send_progress(task_id, 90, "éŸ³é¢‘åˆå¹¶å¤±è´¥ï¼Œä¿ç•™æ— éŸ³é¢‘ç‰ˆæœ¬")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_output):
                os.remove(temp_output)
            return False
        
    except subprocess.TimeoutExpired:
        print("ffmpeg æ‰§è¡Œè¶…æ—¶")
        if task_id:
            await manager.send_progress(task_id, 90, "éŸ³é¢‘å¤„ç†è¶…æ—¶ï¼Œä¿ç•™æ— éŸ³é¢‘ç‰ˆæœ¬")
        return False
    except Exception as e:
        print(f"éŸ³é¢‘åˆå¹¶å¼‚å¸¸: {str(e)}")
        if task_id:
            await manager.send_progress(task_id, 90, f"éŸ³é¢‘å¤„ç†å¼‚å¸¸: {str(e)}")
        return False

async def check_video_has_audio(video_path: str, task_id: str = None) -> bool:
    """
    æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦åŒ…å«éŸ³é¢‘æµ
    
    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
    
    Returns:
        bool: æ˜¯å¦åŒ…å«éŸ³é¢‘
    """
    try:
        # å‘é€è¿›åº¦ï¼šæ£€æµ‹éŸ³é¢‘æµ
        if task_id:
            await manager.send_progress(task_id, 84, "æ£€æµ‹è§†é¢‘ä¸­çš„éŸ³é¢‘æµ...")
        
        cmd = [
            'ffprobe',
            '-v', 'quiet',
            '-select_streams', 'a',
            '-show_entries', 'stream=codec_type',
            '-of', 'csv=p=0',
            video_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        has_audio = result.returncode == 0 and 'audio' in result.stdout
        
        # å‘é€æ£€æµ‹ç»“æœ
        if task_id:
            if has_audio:
                await manager.send_progress(task_id, 85, "å‘ç°éŸ³é¢‘è½¨é“ï¼Œå‡†å¤‡åˆå¹¶...")
            else:
                await manager.send_progress(task_id, 90, "æœªå‘ç°éŸ³é¢‘è½¨é“ï¼Œè·³è¿‡éŸ³é¢‘å¤„ç†")
        
        return has_audio
        
    except Exception as e:
        print(f"âš ï¸ æ£€æŸ¥éŸ³é¢‘æµå¤±è´¥: {str(e)}")
        if task_id:
            await manager.send_progress(task_id, 90, f"éŸ³é¢‘æ£€æµ‹å¤±è´¥: {str(e)}")
        return False

# å¼‚æ­¥éŸ³é¢‘å¤„ç†å‡½æ•°
async def process_audio_async(original_video_path: str, ascii_video_path: str, task_id: str) -> str:
    """
    å¼‚æ­¥å¤„ç†éŸ³é¢‘åˆå¹¶
    
    Args:
        original_video_path: åŸå§‹è§†é¢‘æ–‡ä»¶è·¯å¾„
        ascii_video_path: ASCIIè§†é¢‘æ–‡ä»¶è·¯å¾„
        task_id: ä»»åŠ¡ID
    
    Returns:
        str: æœ€ç»ˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    try:
        # æ£€æŸ¥åŸè§†é¢‘æ˜¯å¦æœ‰éŸ³é¢‘
        if await check_video_has_audio(original_video_path, task_id):
            print(f"åŸè§†é¢‘åŒ…å«éŸ³é¢‘ï¼Œå¼€å§‹åˆå¹¶...")
            
            # åˆ›å»ºå¸¦éŸ³é¢‘çš„æœ€ç»ˆè¾“å‡ºæ–‡ä»¶
            final_output = f"data/{str(uuid.uuid4())}_with_audio.mp4"
            
            # åˆå¹¶éŸ³é¢‘
            if await merge_audio_with_video(original_video_path, ascii_video_path, final_output, task_id):
                # æˆåŠŸåˆå¹¶ï¼Œåˆ é™¤æ— éŸ³é¢‘ç‰ˆæœ¬
                if os.path.exists(ascii_video_path):
                    os.remove(ascii_video_path)
                
                print(f"éŸ³é¢‘åˆå¹¶æˆåŠŸï¼æœ€ç»ˆæ–‡ä»¶: {final_output}")
                return final_output
            else:
                print(f"éŸ³é¢‘åˆå¹¶å¤±è´¥ï¼Œä¿ç•™æ— éŸ³é¢‘ç‰ˆæœ¬")
                return ascii_video_path
        else:
            print(f"åŸè§†é¢‘ä¸åŒ…å«éŸ³é¢‘æµï¼Œè·³è¿‡éŸ³é¢‘å¤„ç†")
            return ascii_video_path
            
    except Exception as e:
        print(f"éŸ³é¢‘å¤„ç†å¼‚å¸¸: {str(e)}")
        await manager.send_progress(task_id, 90, f"éŸ³é¢‘å¤„ç†å¼‚å¸¸: {str(e)}")
        return ascii_video_path


class Args:
    def __init__(self, input_file_path: str, mode: str, background: str, num_cols: int, scale: int, fps: int,
                 overlay_ratio: float, keep_aspect_ratio: bool = True, target_width: int = None, target_height: int = None):
        self.input = input_file_path
        self.output = f"data/{str(uuid.uuid4())}.mp4"
        self.mode = mode
        self.background = background
        self.num_cols = num_cols
        self.scale = scale
        self.fps = fps
        self.overlay_ratio = overlay_ratio
        self.keep_aspect_ratio = keep_aspect_ratio
        self.target_width = target_width
        self.target_height = target_height


def get_args(input_file_path: str, mode: str = "complex", background: str = "black",
             num_cols: int = 100, scale: int = 1, fps: int = 30, overlay_ratio: float = 0.2,
             keep_aspect_ratio: bool = True, target_width: int = None, target_height: int = None):
    return Args(input_file_path, mode, background, num_cols, scale, fps, overlay_ratio, 
                keep_aspect_ratio, target_width, target_height)





def process_frame_ultra_fast(frame, char_list, num_chars, num_cols, num_rows, cell_width, cell_height, 
                            final_width, final_height, bg_code):
    """
    è¶…éŸ³é€Ÿå¸§å¤„ç† - å®Œå…¨è·³è¿‡å­—ç¬¦æ¸²æŸ“ï¼Œç›´æ¥ç”¨é¢œè‰²å—æ¨¡æ‹Ÿ
    """
    height, width = frame.shape[:2]
    
    # ç›´æ¥åˆ›å»ºè¾“å‡ºæ•°ç»„
    out_image = np.full((final_height, final_width, 3), bg_code, dtype=np.uint8)
    
    # è®¡ç®—æ¯ä¸ªåŒºåŸŸçš„å°ºå¯¸
    cell_h = final_height // num_rows
    cell_w = final_width // num_cols
    
    # æ‰¹é‡å¤„ç† - çŸ¢é‡åŒ–æ“ä½œ
    for i in range(num_rows):
        for j in range(num_cols):
            # åŸå§‹å¸§åŒºåŸŸ
            y1, y2 = int(i * cell_height), min(int((i + 1) * cell_height), height)
            x1, x2 = int(j * cell_width), min(int((j + 1) * cell_width), width)
            
            # è¾“å‡ºä½ç½®
            out_y1, out_y2 = i * cell_h, min((i + 1) * cell_h, final_height)
            out_x1, out_x2 = j * cell_w, min((j + 1) * cell_w, final_width)
            
            if y2 > y1 and x2 > x1 and out_y2 > out_y1 and out_x2 > out_x1:
                # è¶…å¿«é€Ÿè®¡ç®—
                cell = frame[y1:y2, x1:x2]
                if cell.size > 0:
                    # ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰éœ€è¦çš„å€¼
                    avg_color = np.mean(cell, axis=(0, 1)).astype(np.uint8)
                    brightness = np.mean(cell)
                    
                    # æ ¹æ®äº®åº¦è°ƒæ•´é¢œè‰²å¼ºåº¦ï¼ˆæ¨¡æ‹Ÿå­—ç¬¦å¯†åº¦ï¼‰
                    char_idx = min(int(brightness * num_chars / 255), num_chars - 1)
                    intensity = char_idx / num_chars
                    
                    # åˆ›å»ºå¸¦æœ‰å­—ç¬¦ç‰¹å¾çš„é¢œè‰²
                    # äº®åº¦é«˜çš„åœ°æ–¹ç”¨äº®è‰²ï¼Œæš—çš„åœ°æ–¹ç”¨æš—è‰²
                    if intensity > 0.7:  # äº®å­—ç¬¦åŒºåŸŸ
                        final_color = (avg_color * 0.9).astype(np.uint8)
                    elif intensity > 0.4:  # ä¸­ç­‰å­—ç¬¦åŒºåŸŸ
                        final_color = (avg_color * 0.6).astype(np.uint8)
                    else:  # æš—å­—ç¬¦åŒºåŸŸ
                        final_color = (avg_color * 0.3).astype(np.uint8)
                    
                    # ç›´æ¥å¡«å……åŒºåŸŸ
                    out_image[out_y1:out_y2, out_x1:out_x2] = final_color
    
    return out_image


def create_char_cache(char_list, font, char_width, char_height, bg_code):
    """
    é¢„æ¸²æŸ“å­—ç¬¦ç¼“å­˜ - ä¸€æ¬¡æ€§æ¸²æŸ“æ‰€æœ‰å­—ç¬¦ï¼Œåç»­ç›´æ¥æ‹·è´
    """
    print(f"ğŸ”¥ åˆ›å»ºå­—ç¬¦ç¼“å­˜: {len(char_list)}ä¸ªå­—ç¬¦...")
    
    char_cache = {}
    
    for char in char_list:
        # åˆ›å»ºå­—ç¬¦æ¨¡æ¿ï¼ˆç™½è‰²å­—ç¬¦ï¼Œé€æ˜èƒŒæ™¯ï¼‰
        char_img = Image.new("RGBA", (char_width, char_height), (0, 0, 0, 0))
        draw = ImageDraw.Draw(char_img)
        draw.text((0, 0), char, fill=(255, 255, 255, 255), font=font)
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶æå–alphaé€šé“
        char_array = np.array(char_img)
        alpha_mask = char_array[:, :, 3] / 255.0  # å½’ä¸€åŒ–alphaé€šé“
        
        # å­˜å‚¨alphaæ©ç ï¼ˆç”¨äºåç»­é¢œè‰²æ··åˆï¼‰
        char_cache[char] = alpha_mask
    
    print(f"âœ… å­—ç¬¦ç¼“å­˜åˆ›å»ºå®Œæˆ!")
    return char_cache


def process_frame_cached_chars(frame, char_list, num_chars, num_cols, num_rows, cell_width, cell_height, 
                              final_width, final_height, bg_code, char_cache, char_width, char_height):
    """
    ç¼“å­˜å­—ç¬¦æ¸²æŸ“ - ä½¿ç”¨é¢„æ¸²æŸ“ç¼“å­˜ï¼Œè¶…å¿«é€Ÿåº¦
    """
    height, width = frame.shape[:2]
    
    # åˆ›å»ºè¾“å‡ºå›¾åƒ
    out_image = np.full((final_height, final_width, 3), bg_code, dtype=np.uint8)
    
    # è®¡ç®—å­—ç¬¦åœ¨ç”»å¸ƒä¸Šçš„é—´è·
    char_spacing_w = final_width / num_cols
    char_spacing_h = final_height / num_rows
    
    for i in range(num_rows):
        for j in range(num_cols):
            # åŸå§‹å¸§åŒºåŸŸ
            y1, y2 = int(i * cell_height), min(int((i + 1) * cell_height), height)
            x1, x2 = int(j * cell_width), min(int((j + 1) * cell_width), width)
            
            if y2 > y1 and x2 > x1:
                # å¿«é€Ÿæå–å•å…ƒæ ¼
                cell = frame[y1:y2, x1:x2]
                if cell.size > 0:
                    # numpyå¿«é€Ÿè®¡ç®—
                    avg_color = np.mean(cell, axis=(0, 1)).astype(np.uint8)
                    brightness = np.mean(cell)
                    
                    # é€‰æ‹©å­—ç¬¦
                    char_idx = min(int(brightness * num_chars / 255), num_chars - 1)
                    char = char_list[char_idx]
                    
                    # è®¡ç®—å­—ç¬¦ä½ç½®
                    char_x = int(j * char_spacing_w + (char_spacing_w - char_width) / 2)
                    char_y = int(i * char_spacing_h + (char_spacing_h - char_height) / 2)
                    
                    # ç¡®ä¿ä¸è¶Šç•Œ
                    end_x = min(char_x + char_width, final_width)
                    end_y = min(char_y + char_height, final_height)
                    
                    if char_x >= 0 and char_y >= 0 and end_x > char_x and end_y > char_y:
                        # è·å–å­—ç¬¦çš„alphaæ©ç 
                        alpha_mask = char_cache[char]
                        
                        # è°ƒæ•´æ©ç å°ºå¯¸ä»¥åŒ¹é…å®é™…åŒºåŸŸ
                        actual_w = end_x - char_x
                        actual_h = end_y - char_y
                        
                        if actual_w != char_width or actual_h != char_height:
                            # éœ€è¦è°ƒæ•´å°ºå¯¸
                            alpha_resized = cv2.resize(alpha_mask, (actual_w, actual_h))
                        else:
                            alpha_resized = alpha_mask
                        
                        # è·å–ç›®æ ‡åŒºåŸŸ
                        target_region = out_image[char_y:end_y, char_x:end_x]
                        
                        # ä½¿ç”¨alphaæ··åˆæ¸²æŸ“å­—ç¬¦
                        alpha_3d = np.stack([alpha_resized] * 3, axis=2)
                        colored_char = avg_color * alpha_3d
                        background = target_region * (1 - alpha_3d)
                        
                        # æ··åˆç»“æœ
                        out_image[char_y:end_y, char_x:end_x] = (colored_char + background).astype(np.uint8)
    
    return out_image


def main_cached_ascii(opt, char_list, num_chars, bg_code, fps, final_width, final_height):
    """
    ç¼“å­˜ASCIIå¤„ç† - é¢„æ¸²æŸ“å­—ç¬¦ç¼“å­˜ï¼ŒçœŸå®å­—ç¬¦ + é«˜æ€§èƒ½
    """
    cap = cv2.VideoCapture(opt.input)
    
    # è·å–è§†é¢‘ä¿¡æ¯
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    height, width = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    
    print(f"ç¼“å­˜ASCIIæ¨¡å¼å¯åŠ¨!")
    print(f"è§†é¢‘: {width}x{height}, {total_frames}å¸§")
    
    # åˆ›å»ºå­—ä½“ - ç¨å¾®å¢å¤§å­—ç¬¦å°ºå¯¸
    font_size = max(10, int(14 * opt.scale))  # æœ€å°14åƒç´ ï¼Œé»˜è®¤18åƒç´ 
    font = ImageFont.truetype("fonts/DejaVuSansMono-Bold.ttf", size=font_size)
    left, top, right, bottom = font.getbbox("A")
    char_width = right - left
    char_height = bottom - top
    
    # åˆ›å»ºå­—ç¬¦ç¼“å­˜ï¼ˆå…³é”®ä¼˜åŒ–ï¼ï¼‰
    char_cache = create_char_cache(char_list, font, char_width, char_height, bg_code)
    
    # æ™ºèƒ½ç½‘æ ¼è®¡ç®— - æ ¹æ®å­—ç¬¦å¤§å°è°ƒæ•´
    max_cols = final_width // char_width  # æ ¹æ®å­—ç¬¦å®½åº¦è®¡ç®—æœ€å¤§åˆ—æ•°
    num_cols = min(opt.num_cols, max_cols, 100)  # é™åˆ¶æœ€å¤§åˆ—æ•°
    num_rows = max(1, final_height // (char_height + 2))  # ç•™ä¸€ç‚¹é—´è·
    
    # ç¡®ä¿åˆç†çš„ç½‘æ ¼å¤§å°
    if num_cols * char_width > final_width:
        num_cols = final_width // char_width
    if num_rows * char_height > final_height:
        num_rows = final_height // char_height
    
    cell_width = width / num_cols
    cell_height = height / num_rows
    
    print(f"ğŸ¯ ASCIIç½‘æ ¼: {num_cols}x{num_rows}å­—ç¬¦")
    print(f"ğŸ“ å­—ç¬¦å°ºå¯¸: {char_width}x{char_height}px")
    
    # åˆ›å»ºè§†é¢‘å†™å…¥å™¨ - ä½¿ç”¨æµè§ˆå™¨å…¼å®¹çš„ç¼–ç 
    # å°è¯•H264ï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨XVID
    try:
        fourcc = cv2.VideoWriter_fourcc(*'H264')
        out = cv2.VideoWriter(opt.output, fourcc, fps, (final_width, final_height))
        if not out.isOpened():
            raise Exception("H264 not available")
    except:
        print("âš ï¸ H264ç¼–ç ä¸å¯ç”¨ï¼Œä½¿ç”¨XVIDç¼–ç ")
        fourcc = cv2.VideoWriter_fourcc(*'XVID')
        # æ›´æ”¹æ–‡ä»¶æ‰©å±•åä¸º.aviä»¥åŒ¹é…XVID
        opt.output = opt.output.replace('.mp4', '.avi')
        out = cv2.VideoWriter(opt.output, fourcc, fps, (final_width, final_height))
    
    # ä¼˜åŒ–çš„å¹¶è¡Œè®¾ç½®
    available_cores = multiprocessing.cpu_count()
    batch_size = min(available_cores * 2, 16)  # å¹³è¡¡æ‰¹æ¬¡å¤§å°
    
    print(f"ğŸ’ª ä½¿ç”¨ {available_cores} æ ¸å¿ƒ, æ‰¹æ¬¡: {batch_size}")
    
    processed_frames = 0
    start_time = time.time()
    
    # é«˜æ•ˆå¹¶è¡Œå¤„ç†
    with ThreadPoolExecutor(max_workers=available_cores) as executor:
        while True:
            # è¯»å–æ‰¹æ¬¡å¸§
            frames_batch = []
            original_frames = []
            
            for _ in range(batch_size):
                ret, frame = cap.read()
                if not ret:
                    break
                frames_batch.append(frame)
                if opt.overlay_ratio > 0:
                    original_frames.append(frame.copy())
            
            if not frames_batch:
                break
            
            # ä½¿ç”¨ç¼“å­˜å­—ç¬¦æ¸²æŸ“
            process_func = partial(
                process_frame_cached_chars,
                char_list=char_list,
                num_chars=num_chars,
                num_cols=num_cols,
                num_rows=num_rows,
                cell_width=cell_width,
                cell_height=cell_height,
                final_width=final_width,
                final_height=final_height,
                bg_code=bg_code,
                char_cache=char_cache,
                char_width=char_width,
                char_height=char_height
            )
            
            # å¹¶è¡Œæäº¤æ‰€æœ‰å¸§
            futures = [executor.submit(process_func, frame) for frame in frames_batch]
            
            # å¿«é€Ÿæ”¶é›†å¹¶å†™å…¥
            for i, future in enumerate(futures):
                result_frame = future.result()
                
                # å¿«é€Ÿå åŠ å±‚
                if opt.overlay_ratio > 0 and i < len(original_frames):
                    h, w = result_frame.shape[:2]
                    overlay_h, overlay_w = int(h * opt.overlay_ratio), int(w * opt.overlay_ratio)
                    overlay = cv2.resize(original_frames[i], (overlay_w, overlay_h))
                    result_frame[h - overlay_h:, w - overlay_w:] = overlay
                
                out.write(result_frame)
                processed_frames += 1
                
                # è¿›åº¦æ˜¾ç¤º
                if processed_frames % 60 == 0:
                    progress = processed_frames / total_frames * 100
                    elapsed = time.time() - start_time
                    speed = processed_frames / elapsed if elapsed > 0 else 0
                    eta = (total_frames - processed_frames) / speed if speed > 0 else 0
                    print(f"ğŸš€ ç¼“å­˜è¿›åº¦: {progress:.1f}% ({processed_frames}/{total_frames}) "
                          f"é€Ÿåº¦: {speed:.1f}fps, é¢„è®¡å®Œæˆ: {eta:.0f}s")
    
    cap.release()
    out.release()
    
    total_time = time.time() - start_time
    avg_fps = total_frames / total_time if total_time > 0 else 0
    print(f"ç¼“å­˜å¤„ç†å®Œæˆ! ç”¨æ—¶: {total_time:.1f}s, å¹³å‡é€Ÿåº¦: {avg_fps:.1f}fps")
    print(f"è¾“å‡º: {opt.output}")
    
    # æ€§èƒ½åˆ†æ
    if total_time > 90:  # è¶…è¿‡1.5åˆ†é’Ÿ
        print("æ€§èƒ½æç¤º: å¤„ç†æ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®:")
        print("   1. é™ä½num_colså‚æ•° (å»ºè®®50-80)")
        print("   2. å‡å°‘overlay_ratio")
        print("   3. ä½¿ç”¨mode='simple'")
    elif total_time < 45:  # å°äº45ç§’
        print("æ€§èƒ½ä¼˜ç§€! ç¼“å­˜ç³»ç»Ÿå·¥ä½œå®Œç¾!")


def main(opt):
    if opt.mode == "simple":
        CHAR_LIST = '@%#*+=-:. '
    else:
        CHAR_LIST = r"$@B%8&WM#*oahkbdpqwmZO0QLCJUYXzcvunxrjft/\|()1{}[]?-_+~<>i!lI;:,\"^`'. "
    if opt.background == "white":
        bg_code = (255, 255, 255)
    else:
        bg_code = (0, 0, 0)
    
    cap = cv2.VideoCapture(opt.input)
    if opt.fps == 0:
        fps = int(cap.get(cv2.CAP_PROP_FPS))
    else:
        fps = opt.fps
    num_chars = len(CHAR_LIST)
    
    # è·å–åŸå§‹è§†é¢‘å°ºå¯¸
    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    # ç¡®å®šæœ€ç»ˆè¾“å‡ºå°ºå¯¸
    if opt.target_width and opt.target_height:
        final_width, final_height = opt.target_width, opt.target_height
    elif opt.keep_aspect_ratio:
        if opt.target_width:
            final_width = opt.target_width
            final_height = int(opt.target_width * original_height / original_width)
        elif opt.target_height:
            final_height = opt.target_height
            final_width = int(opt.target_height * original_width / original_height)
        else:
            final_width, final_height = original_width, original_height
    else:
        final_width, final_height = None, None  # ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼
    
    # ç›´æ¥ä½¿ç”¨ç¼“å­˜ASCIIæ¨¡å¼
    if final_width and final_height:
        return main_cached_ascii(opt, CHAR_LIST, num_chars, bg_code, fps, 
                                final_width, final_height)
    
    # ä¼ ç»Ÿæ¨¡å¼ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
    font = ImageFont.truetype("fonts/DejaVuSansMono-Bold.ttf", size=int(10 * opt.scale))
    
    while cap.isOpened():
        flag, frame = cap.read()
        if not flag:
            break
        height, width, _ = frame.shape
        
        # å¦‚æœæŒ‡å®šäº†æœ€ç»ˆå°ºå¯¸ï¼Œé‡æ–°è®¡ç®—å­—ç¬¦å‚æ•°ä»¥å¡«æ»¡æ•´ä¸ªç”»é¢
        if final_width and final_height:
            # è·å–å­—ç¬¦å°ºå¯¸
            left, top, right, bottom = font.getbbox("A")
            char_width = right - left
            char_height = bottom - top
            
            # è®¡ç®—èƒ½å¤Ÿå¡«æ»¡ç›®æ ‡å°ºå¯¸çš„å­—ç¬¦æ•°é‡
            num_cols = max(1, final_width // char_width)
            num_rows = max(1, final_height // (char_height * 2))  # ä¿æŒ2å€é«˜åº¦æ¯”ä¾‹
            
            # é‡æ–°è®¡ç®—å•å…ƒæ ¼å°ºå¯¸ä»¥é€‚åº”åŸå§‹è§†é¢‘
            cell_width = width / num_cols
            cell_height = height / num_rows
            
            # åˆ›å»ºç›®æ ‡å°ºå¯¸çš„ç”»å¸ƒ
            out_image = Image.new("RGB", (final_width, final_height), bg_code)
            draw = ImageDraw.Draw(out_image)
            
            # è®¡ç®—å­—ç¬¦åœ¨ç”»å¸ƒä¸Šçš„å®é™…é—´è·
            actual_char_width = final_width / num_cols
            actual_char_height = final_height / num_rows
            
            for i in range(num_rows):
                for j in range(num_cols):
                    # ä»åŸå§‹å¸§ä¸­æå–å¯¹åº”åŒºåŸŸ
                    partial_image = frame[int(i * cell_height):min(int((i + 1) * cell_height), height),
                                    int(j * cell_width):min(int((j + 1) * cell_width), width), :]
                    
                    if partial_image.size > 0:  # ç¡®ä¿åŒºåŸŸä¸ä¸ºç©º
                        partial_avg_color = np.mean(partial_image, axis=(0, 1)).astype(np.int32)
                        partial_avg_color = tuple(partial_avg_color.tolist())
                        char = CHAR_LIST[min(int(np.mean(partial_image) * num_chars / 255), num_chars - 1)]
                        
                        # åœ¨ç”»å¸ƒä¸Šç»˜åˆ¶å­—ç¬¦ï¼Œå±…ä¸­å¯¹é½
                        x = int(j * actual_char_width + (actual_char_width - char_width) / 2)
                        y = int(i * actual_char_height + (actual_char_height - char_height) / 2)
                        draw.text((x, y), char, fill=partial_avg_color, font=font)
        else:
            # ä¼ ç»Ÿæ¨¡å¼
            cell_width = width / opt.num_cols
            cell_height = 2 * cell_width
            num_rows = int(height / cell_height)
            num_cols = opt.num_cols
            
            if num_cols > width or num_rows > height:
                print("Too many columns or rows. Use default setting")
                cell_width = 6
                cell_height = 12
                num_cols = int(width / cell_width)
                num_rows = int(height / cell_height)
            
            left, top, right, bottom = font.getbbox("A")
            char_width = right - left
            char_height = bottom - top
            out_width = char_width * num_cols
            out_height = 2 * char_height * num_rows
            out_image = Image.new("RGB", (out_width, out_height), bg_code)
            draw = ImageDraw.Draw(out_image)
            
            for i in range(num_rows):
                for j in range(num_cols):
                    partial_image = frame[int(i * cell_height):min(int((i + 1) * cell_height), height),
                                    int(j * cell_width):min(int((j + 1) * cell_width), width), :]
                    partial_avg_color = np.sum(np.sum(partial_image, axis=0), axis=0) / (cell_height * cell_width)
                    partial_avg_color = tuple(partial_avg_color.astype(np.int32).tolist())
                    char = CHAR_LIST[min(int(np.mean(partial_image) * num_chars / 255), num_chars - 1)]
                    draw.text((j * char_width, i * char_height), char, fill=partial_avg_color, font=font)

            # ä¼ ç»Ÿæ¨¡å¼çš„è£å‰ªé€»è¾‘
            if opt.background == "white":
                cropped_image = ImageOps.invert(out_image).getbbox()
            else:
                cropped_image = out_image.getbbox()
            if cropped_image:
                out_image = out_image.crop(cropped_image)
        
        out_image = np.array(out_image)
        try:
            out
        except:
            out = cv2.VideoWriter(opt.output, cv2.VideoWriter_fourcc(*"H264"), fps,
                                  ((out_image.shape[1], out_image.shape[0])))

        if opt.overlay_ratio:
            height, width, _ = out_image.shape
            overlay = cv2.resize(frame, (int(width * opt.overlay_ratio), int(height * opt.overlay_ratio)))
            out_image[height - int(height * opt.overlay_ratio):, width - int(width * opt.overlay_ratio):, :] = overlay
        out.write(out_image)
    cap.release()
    out.release()


@video.post("/convert_video/")
async def convert_video(
    file: UploadFile = File(...),
    mode: str = Form(default="complex"),
    background: str = Form(default="black"),
    num_cols: int = Form(default=100),
    scale: int = Form(default=1),
    overlay_ratio: float = Form(default=0.2)
):
    # åˆ›å»ºç‹¬ä¸€æ— äºŒçš„è¾“å…¥æ–‡ä»¶å
    input_file_location = f"data/{str(uuid.uuid4())}.mp4"

    # å°†ä¸Šä¼ çš„æ–‡ä»¶ä¿å­˜åˆ°æœåŠ¡å™¨
    with open(input_file_location, "wb") as f:
        content = await file.read()
        f.write(content)

    # ğŸ¬ è‡ªåŠ¨è§£æè§†é¢‘ä¿¡æ¯
    cap = cv2.VideoCapture(input_file_location)
    
    # è·å–åŸå§‹è§†é¢‘å‚æ•°
    original_fps = int(cap.get(cv2.CAP_PROP_FPS))
    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    cap.release()
    
    print(f"ğŸ“¹ è§†é¢‘ä¿¡æ¯è§£æå®Œæˆ:")
    print(f"   å°ºå¯¸: {original_width} x {original_height}")
    print(f"   å¸§ç‡: {original_fps} fps")
    print(f"   æ€»å¸§æ•°: {total_frames} å¸§")
    print(f"   æ—¶é•¿: {total_frames/original_fps:.1f} ç§’")

    # è·å–å¤„ç†å‚æ•°ï¼ˆè‡ªåŠ¨ä½¿ç”¨åŸå§‹è§†é¢‘å‚æ•°ï¼‰
    args = get_args(
        input_file_path=input_file_location,
        mode=mode,
        background=background,
        num_cols=num_cols,
        scale=scale,
        fps=original_fps,  # ğŸ¯ ä½¿ç”¨åŸå§‹å¸§ç‡
        overlay_ratio=overlay_ratio,
        keep_aspect_ratio=True,  # ğŸ¯ å¼ºåˆ¶ä¿æŒå®½é«˜æ¯”
        target_width=original_width,  # ğŸ¯ ä½¿ç”¨åŸå§‹å®½åº¦
        target_height=original_height  # ğŸ¯ ä½¿ç”¨åŸå§‹é«˜åº¦
    )

    try:
        # è°ƒç”¨ä¸»å¤„ç†é€»è¾‘
        main(args)
        
        # æ¸…ç†è¾“å…¥æ–‡ä»¶
        if os.path.exists(input_file_location):
            os.remove(input_file_location)
        
        # è¿”å›è¯¦ç»†çš„å¤„ç†ç»“æœä¿¡æ¯
        return JSONResponse(content={
            "absolute_path": os.path.abspath(args.output),
            "video_info": {
                "original_width": original_width,
                "original_height": original_height,
                "original_fps": original_fps,
                "total_frames": total_frames,
                "duration_seconds": round(total_frames/original_fps, 1)
            },
            "processing_info": {
                "mode": mode,
                "background": background,
                "num_cols": num_cols,
                "scale": scale,
                "overlay_ratio": overlay_ratio
            }
        })
    except Exception as e:
        # æ¸…ç†è¾“å…¥æ–‡ä»¶
        if os.path.exists(input_file_location):
            os.remove(input_file_location)
        return JSONResponse(content={"error": str(e)}, status_code=500)




# ç®€åŒ–çš„åŒæ­¥è§†é¢‘å¤„ç†å‡½æ•°ï¼ˆç”¨äºåœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œï¼‰
def process_video_sync(file_path: str, args: Args, task_id: str):
    """åŒæ­¥å¤„ç†è§†é¢‘è½¬æ¢ä»»åŠ¡ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œï¼‰"""
    try:
        print(f"å¼€å§‹å¤„ç†ä»»åŠ¡: {task_id}")
        
        # ç¡®å®šå­—ç¬¦é›†
        if args.mode == "simple":
            CHAR_LIST = '@%#*+=-:. '
        else:
            CHAR_LIST = r"$@B%8&WM#*oahkbdpqwmZO0QLCJUYXzcvunxrjft/\|()1{}[]?-_+~<>i!lI;:,\"^`'. "
        
        if args.background == "white":
            bg_code = (255, 255, 255)
        else:
            bg_code = (0, 0, 0)
        
        cap = cv2.VideoCapture(args.input)
        if args.fps == 0:
            fps = int(cap.get(cv2.CAP_PROP_FPS))
        else:
            fps = args.fps
        num_chars = len(CHAR_LIST)
        
        # è·å–åŸå§‹è§†é¢‘å°ºå¯¸
        original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        cap.release()
        
        # ç¡®å®šæœ€ç»ˆè¾“å‡ºå°ºå¯¸
        if args.target_width and args.target_height:
            final_width, final_height = args.target_width, args.target_height
        elif args.keep_aspect_ratio:
            if args.target_width:
                final_width = args.target_width
                final_height = int(args.target_width * original_height / original_width)
            elif args.target_height:
                final_height = args.target_height
                final_width = int(args.target_height * original_width / original_height)
            else:
                final_width, final_height = original_width, original_height
        else:
            final_width, final_height = original_width, original_height
        
        print(f"ğŸ“ ç›®æ ‡å°ºå¯¸: {final_width}x{final_height}")
        
        # ä½¿ç”¨ç°æœ‰çš„main_cached_asciiå‡½æ•°å¤„ç†è§†é¢‘
        main_cached_ascii(args, CHAR_LIST, num_chars, bg_code, fps, final_width, final_height)
        
        # æ³¨æ„ï¼šéŸ³é¢‘å¤„ç†å°†åœ¨å¼‚æ­¥ç¯å¢ƒä¸­è¿›è¡Œï¼Œè¿™é‡Œåªè¿”å›æ— éŸ³é¢‘ç‰ˆæœ¬çš„è·¯å¾„
        
        print(f"ASCIIè§†é¢‘ç”Ÿæˆå®Œæˆ: {task_id}")
        return {
            "status": "completed",
            "output_path": args.output,
            "input_path": file_path,  # ä¿ç•™åŸå§‹æ–‡ä»¶è·¯å¾„ç”¨äºéŸ³é¢‘å¤„ç†
            "video_url": f"https://ascii.gyq-me.top/video/download/{os.path.basename(args.output)}"
        }
        
    except Exception as e:
        print(f"ä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {str(e)}")
        # æ¸…ç†è¾“å…¥æ–‡ä»¶
        if os.path.exists(file_path):
            os.remove(file_path)
        
        return {
            "status": "error",
            "error": str(e)
        }


# WebSocketå¤„ç†è§†é¢‘è½¬æ¢çš„å¼‚æ­¥ä»»åŠ¡
async def process_video_task(file_path: str, args: Args, task_id: str):
    """å¼‚æ­¥å¤„ç†è§†é¢‘è½¬æ¢ä»»åŠ¡"""
    try:
        await manager.send_progress(task_id, 0, "ä»»åŠ¡å·²å¯åŠ¨ï¼Œå¼€å§‹å¤„ç†...")
        
        # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥çš„è§†é¢‘å¤„ç†
        import concurrent.futures
        with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
            # å®šæœŸå‘é€è¿›åº¦æ›´æ–°
            loop = asyncio.get_event_loop()
            
            # å¯åŠ¨è§†é¢‘å¤„ç†ä»»åŠ¡
            future = executor.submit(process_video_sync, file_path, args, task_id)
            
            # æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°ï¼ˆå› ä¸ºå®é™…å¤„ç†åœ¨å¦ä¸€ä¸ªçº¿ç¨‹ä¸­ï¼‰
            progress = 5
            while not future.done():
                await asyncio.sleep(2)  # æ¯2ç§’æ›´æ–°ä¸€æ¬¡
                progress = min(progress + 5, 82)  # é€æ­¥å¢åŠ åˆ°82%ï¼Œä¸ºéŸ³é¢‘å¤„ç†ç•™å‡ºç©ºé—´
                await manager.send_progress(task_id, progress, f"å¤„ç†ä¸­...({progress}%)")
            
            # è·å–å¤„ç†ç»“æœ
            result = future.result()
            
            if result["status"] == "completed":
                # ASCII è§†é¢‘ç”Ÿæˆå®Œæˆï¼Œç°åœ¨å¤„ç†éŸ³é¢‘
                ascii_video_path = result["output_path"]
                original_video_path = result["input_path"]
                
                # å¼€å§‹éŸ³é¢‘å¤„ç†
                await manager.send_progress(task_id, 83, "å¼€å§‹éŸ³é¢‘å¤„ç†...")
                
                # å¼‚æ­¥å¤„ç†éŸ³é¢‘åˆå¹¶
                final_video_path = await process_audio_async(original_video_path, ascii_video_path, task_id)
                
                # æ¸…ç†åŸå§‹è¾“å…¥æ–‡ä»¶
                if os.path.exists(original_video_path):
                    os.remove(original_video_path)
                
                # æ›´æ–°æœ€ç»ˆç»“æœ
                final_video_url = f"https://ascii.gyq-me.top/video/download/{os.path.basename(final_video_path)}"
                
                # å‘é€å®Œæˆæ¶ˆæ¯
                await manager.send_progress(task_id, 98, "å¤„ç†å®Œæˆï¼")
                await asyncio.sleep(0.5)
                
                await manager.send_completed(task_id, final_video_url)
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                final_result = result.copy()
                final_result["output_path"] = final_video_path
                final_result["video_url"] = final_video_url
                task_status[task_id] = final_result
            else:
                await manager.send_error(task_id, result["error"])
                task_status[task_id] = result
        
    except Exception as e:
        print(f"å¼‚æ­¥ä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {str(e)}")
        # æ¸…ç†è¾“å…¥æ–‡ä»¶
        if os.path.exists(file_path):
            os.remove(file_path)
        
        # å‘é€é”™è¯¯æ¶ˆæ¯
        await manager.send_error(task_id, str(e))
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task_status[task_id] = {
            "status": "error",
            "error": str(e)
        }


# WebSocketç«¯ç‚¹
@video.websocket("/ws/{task_id}")
async def websocket_endpoint(websocket: WebSocket, task_id: str):
    await manager.connect(websocket, task_id)
    try:
        while True:
            # ä¿æŒè¿æ¥æ´»è·ƒ
            await websocket.receive_text()
    except WebSocketDisconnect:
        manager.disconnect(task_id)


# å¯åŠ¨è§†é¢‘è½¬æ¢ä»»åŠ¡çš„API
@video.post("/convert_video_ws/")
async def convert_video_ws(
    file: UploadFile = File(...),
    mode: str = Form(default="complex"),
    background: str = Form(default="black"),
    num_cols: int = Form(default=80),
    scale: int = Form(default=1),
    overlay_ratio: float = Form(default=0.0)
):
    """å¯åŠ¨WebSocketè§†é¢‘è½¬æ¢ä»»åŠ¡"""
    # ç”Ÿæˆä»»åŠ¡ID
    task_id = str(uuid.uuid4())
    
    # åˆ›å»ºè¾“å…¥æ–‡ä»¶
    input_file_location = f"data/{task_id}_input.mp4"
    
    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
    with open(input_file_location, "wb") as f:
        content = await file.read()
        f.write(content)
    
    # è·å–è§†é¢‘ä¿¡æ¯
    cap = cv2.VideoCapture(input_file_location)
    original_fps = int(cap.get(cv2.CAP_PROP_FPS))
    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    cap.release()
    
    print(f"æ¥æ”¶åˆ°å‚æ•°: mode={mode}, overlay_ratio={overlay_ratio}, num_cols={num_cols}")
    
    # åˆ›å»ºå¤„ç†å‚æ•°
    args = get_args(
        input_file_path=input_file_location,
        mode=mode,
        background=background,
        num_cols=num_cols,
        scale=scale,
        fps=original_fps,
        overlay_ratio=overlay_ratio,  # ä½¿ç”¨å‰ç«¯ä¼ å…¥çš„å‚æ•°
        keep_aspect_ratio=True,
        target_width=original_width,
        target_height=original_height
    )
    
    # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
    task_status[task_id] = {
        "status": "processing",
        "video_info": {
            "original_width": original_width,
            "original_height": original_height,
            "original_fps": original_fps,
            "total_frames": total_frames,
            "duration_seconds": round(total_frames/original_fps, 1)
        }
    }
    
    # å¯åŠ¨å¼‚æ­¥ä»»åŠ¡
    try:
        asyncio.create_task(process_video_task(input_file_location, args, task_id))
        print(f"ä»»åŠ¡å·²å¯åŠ¨: {task_id}")
    except Exception as e:
        print(f"å¯åŠ¨ä»»åŠ¡å¤±è´¥: {str(e)}")
        return JSONResponse(content={"error": f"å¯åŠ¨ä»»åŠ¡å¤±è´¥: {str(e)}"}, status_code=500)
    
    return {"task_id": task_id, "message": "ä»»åŠ¡å·²å¯åŠ¨ï¼Œè¯·é€šè¿‡WebSocketè¿æ¥è·å–è¿›åº¦"}


# ä¸‹è½½ç”Ÿæˆçš„è§†é¢‘
@video.get("/download/{filename}")
async def download_video(filename: str):
    """ä¸‹è½½ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶"""
    file_path = f"data/{filename}"
    if os.path.exists(file_path):
        from fastapi.responses import FileResponse
        response = FileResponse(
            path=file_path,
            filename=filename,
            media_type='video/mp4'
        )
        # æ·»åŠ CORSå¤´æ”¯æŒè§†é¢‘æ’­æ”¾
        # response.headers["Access-Control-Allow-Origin"] = "*"
        # response.headers["Access-Control-Allow-Methods"] = "GET"
        # response.headers["Access-Control-Allow-Headers"] = "*"
        response.headers["Accept-Ranges"] = "bytes"
        return response
    else:
        return JSONResponse(content={"error": "æ–‡ä»¶ä¸å­˜åœ¨"}, status_code=404)


# æ‰‹åŠ¨æ¸…ç†å‘½ä»¤ï¼ˆå¯é€‰ï¼‰
@video.post("/manual_cleanup/")
async def manual_cleanup():
    """æ‰‹åŠ¨è§¦å‘æ¸…ç†è¿‡æœŸè§†é¢‘æ–‡ä»¶"""
    await cleanup_old_videos()
    return {"message": "æ‰‹åŠ¨æ¸…ç†ä»»åŠ¡å·²æ‰§è¡Œ"}

# è·å–æ¸…ç†çŠ¶æ€
@video.get("/cleanup_status/")
async def cleanup_status():
    """è·å–å®šæ—¶æ¸…ç†çŠ¶æ€ä¿¡æ¯"""
    data_dir = "data/"
    if not os.path.exists(data_dir):
        return {"status": "dataç›®å½•ä¸å­˜åœ¨", "files": 0, "total_size": 0}
    
    media_files = []
    total_size = 0
    
    media_patterns = [
        os.path.join(data_dir, "*.mp4"),
        os.path.join(data_dir, "*.avi"),
        os.path.join(data_dir, "*.mov"),
        os.path.join(data_dir, "*.jpg"),
        os.path.join(data_dir, "*.jpeg"),
        os.path.join(data_dir, "*.png")
    ]
    
    for pattern in media_patterns:
        for file_path in glob.glob(pattern):
            try:
                file_size = os.path.getsize(file_path)
                file_mtime = os.path.getmtime(file_path)
                file_age_hours = (datetime.now().timestamp() - file_mtime) / 3600
                
                media_files.append({
                    "filename": os.path.basename(file_path),
                    "size_mb": round(file_size / 1024 / 1024, 2),
                    "age_hours": round(file_age_hours, 1),
                    "will_be_deleted": file_age_hours > 24
                })
                total_size += file_size
            except Exception as e:
                print(f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥ {file_path}: {str(e)}")
    
    return {
        "scheduler_running": scheduler.running,
        "total_files": len(media_files),
        "total_size_mb": round(total_size / 1024 / 1024, 2),
        "files": media_files,
        "next_cleanup": "æ¯å¤©å‡Œæ™¨2ç‚¹"
    }

# å¯åŠ¨å®šæ—¶æ¸…ç†è°ƒåº¦å™¨
try:
    start_cleanup_scheduler()
except Exception as e:
    print(f"å®šæ—¶æ¸…ç†è°ƒåº¦å™¨å¯åŠ¨å¤±è´¥: {str(e)}")

# è¿è¡Œåº”ç”¨
# uvicorn your_script_name:app --reload
